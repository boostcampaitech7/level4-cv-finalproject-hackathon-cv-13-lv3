{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AudioTextDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        self.dirname = os.path.dirname(json_path)\n",
    "        with open(json_path, \"r\") as f:\n",
    "            self.data = json.load(f)[\"annotation\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        audio_path = os.path.join(self.dirname, entry[\"path\"])\n",
    "        text = entry[\"text\"]\n",
    "\n",
    "        try:\n",
    "            # torchaudio를 사용하여 로드 및 리샘플링 (mono 변환)\n",
    "            waveform, sr = torchaudio.load(audio_path)\n",
    "            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=48000)(waveform)\n",
    "            waveform = torch.mean(waveform, dim=0)  # 스테레오 → 모노 변환\n",
    "        except Exception as e:\n",
    "            print(f\"오디오 로드 실패: {audio_path} - {str(e)}\")\n",
    "            return None  # 실패한 경우 None 반환\n",
    "\n",
    "        return {\"waveform\": waveform, \"text\": text, \"path\": audio_path}\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"DataLoader에서 None 값 제거 및 배치 변환\"\"\"\n",
    "    batch = [b for b in batch if b is not None]  # None 제거\n",
    "    if len(batch) == 0:\n",
    "        return None  # 빈 배치 방지\n",
    "\n",
    "    waveforms = [b[\"waveform\"] for b in batch]\n",
    "    texts = [b[\"text\"] for b in batch]\n",
    "    paths = [b[\"path\"] for b in batch]\n",
    "\n",
    "    return {\"waveforms\": torch.stack(waveforms), \"texts\": texts, \"paths\": paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    \"\"\"멀티 GPU 환경 설정\"\"\"\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"프로세스 종료\"\"\"\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "# CLAP 모델 경로\n",
    "MODEL_NAME = \"laion/clap-htsat-unfused\"\n",
    "\n",
    "def clap_refine(rank, world_size, input_json_path, output_json_path, batch_size=8, similarity_threshold=0.5):\n",
    "    \"\"\"멀티 GPU를 활용한 CLAP 유사도 필터링\"\"\"\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    processor = ClapProcessor.from_pretrained(MODEL_NAME)\n",
    "    model = ClapModel.from_pretrained(MODEL_NAME).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = AudioTextDataset(input_json_path)\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "\n",
    "    filtered_annotations = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        waveforms = batch[\"waveforms\"].to(device)\n",
    "        texts = batch[\"texts\"]\n",
    "        paths = batch[\"paths\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 오디오 및 텍스트 임베딩 생성\n",
    "            inputs = processor(audios=[w.cpu().numpy() for w in waveforms], return_tensors=\"pt\", sampling_rate=48000)\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "            text_inputs = processor(text=texts, return_tensors=\"pt\")\n",
    "            text_inputs = {key: val.to(device) for key, val in text_inputs.items()}\n",
    "\n",
    "            audio_embeds = model.get_audio_features(**inputs)\n",
    "            text_embeds = model.get_text_features(**text_inputs)\n",
    "\n",
    "            similarities = F.cosine_similarity(audio_embeds, text_embeds).cpu().numpy()\n",
    "\n",
    "        # 임계값 체크 후 저장\n",
    "        for i, sim in enumerate(similarities):\n",
    "            if sim >= similarity_threshold:\n",
    "                filtered_annotations.append({\"path\": paths[i], \"text\": texts[i]})\n",
    "                print(f\"[GPU {rank}] 유지: {paths[i]} - 유사도: {sim:.4f}\")\n",
    "            else:\n",
    "                print(f\"[GPU {rank}] 제거: {paths[i]} - 유사도: {sim:.4f}\")\n",
    "\n",
    "    # 모든 GPU의 데이터를 모아서 저장\n",
    "    gathered_data = [None] * world_size\n",
    "    dist.all_gather_object(gathered_data, filtered_annotations)\n",
    "\n",
    "    if rank == 0:\n",
    "        all_filtered = [item for sublist in gathered_data for item in sublist]\n",
    "        with open(output_json_path, \"w\") as f:\n",
    "            json.dump({\"annotation\": all_filtered}, f, indent=4)\n",
    "        print(f\"필터링 완료! {len(all_filtered)}개 항목 저장됨\")\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 GPU 수: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/root/miniconda3/envs/salmonn/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/root/miniconda3/envs/salmonn/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'clap_refine' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/root/miniconda3/envs/salmonn/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/root/miniconda3/envs/salmonn/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'clap_refine' on <module '__main__' (built-in)>\n",
      "W0204 19:15:07.196000 588919 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 616937 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m사용 가능한 GPU 수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworld_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     mp\u001b[38;5;241m.\u001b[39mspawn(\n\u001b[1;32m      9\u001b[0m         clap_refine,\n\u001b[1;32m     10\u001b[0m         args\u001b[38;5;241m=\u001b[39m(world_size, input_json_path, output_json_path, batch_size),\n\u001b[1;32m     11\u001b[0m         nprocs\u001b[38;5;241m=\u001b[39mworld_size,\n\u001b[1;32m     12\u001b[0m         join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/dataset/stage1_sample1.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(input_json_path, output_json_path, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m world_size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m사용 가능한 GPU 수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworld_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclap_refine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:328\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    322\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:284\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:192\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    186\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    194\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    195\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    196\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_files[error_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    200\u001b[0m     original_trace \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "def main(input_json_path=\"input.json\", output_json_path=\"output.json\", batch_size=8):\n",
    "    \"\"\"멀티 GPU 실행\"\"\"\n",
    "    world_size = torch.cuda.device_count()\n",
    "    print(f\"사용 가능한 GPU 수: {world_size}\")\n",
    "\n",
    "    mp.spawn(\n",
    "        clap_refine,\n",
    "        args=(world_size, input_json_path, output_json_path, batch_size),\n",
    "        nprocs=world_size,\n",
    "        join=True,\n",
    "    )\n",
    "\n",
    "main(\"/data/dataset/stage1_sample1.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
