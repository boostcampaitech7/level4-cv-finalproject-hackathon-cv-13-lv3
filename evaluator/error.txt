(salmonn) root@nota-gpu-svr002:/data/jins/level4-cv-finalproject-hackathon-cv-13-lv3/evaluator# python tensorrt_aot.py 
/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch_tensorrt/fx/tracer/acc_tracer/acc_ops.py:895: UserWarning: Unable to import torchvision related libraries.: No module named 'torchvision'. Please install torchvision lib in order to lower stochastic_depth
  warnings.warn(
Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.34it/s]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
WARNING:py.warnings:/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)

BertLMHeadModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Loading training prompts done!
E0203 17:49:18.045000 1438110 site-packages/torch/export/_trace.py:1003] always_classified is unsupported.
Error in compile_group_2: Failed running call_module L__self___model_embed_tokens(*(FakeTensor(..., device='cuda:0', size=(8, 111, 3072), dtype=torch.float16),), **{}):
tensors used as indices must be long, int, byte or bool tensors

from user code:
   File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 831, in forward
    outputs = self.model(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 545, in forward
    inputs_embeds = self.embed_tokens(input_ids)

Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information

Traceback (most recent call last):
  File "/data/jins/level4-cv-finalproject-hackathon-cv-13-lv3/evaluator/tensorrt_aot.py", line 335, in <module>
    main()
  File "/data/jins/level4-cv-finalproject-hackathon-cv-13-lv3/evaluator/tensorrt_aot.py", line 308, in main
    compile_group_2(salmonn_preprocessor.llama_model)
  File "/data/jins/level4-cv-finalproject-hackathon-cv-13-lv3/evaluator/tensorrt_aot.py", line 283, in compile_group_2
    raise e
  File "/data/jins/level4-cv-finalproject-hackathon-cv-13-lv3/evaluator/tensorrt_aot.py", line 280, in compile_group_2
    save_llm_trt(llm)
  File "/data/jins/level4-cv-finalproject-hackathon-cv-13-lv3/evaluator/tensorrt_aot.py", line 202, in save_llm_trt
    llm = torch_tensorrt.compile(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch_tensorrt/_compile.py", line 266, in compile
    exp_program = dynamo_trace(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch_tensorrt/dynamo/_tracer.py", line 83, in trace
    exp_program = export(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/__init__.py", line 270, in export
    return _export(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/_trace.py", line 1017, in wrapper
    raise e
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/_trace.py", line 990, in wrapper
    ep = fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/exported_program.py", line 114, in wrapper
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/_trace.py", line 1880, in _export
    export_artifact = export_func(  # type: ignore[operator]
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/_trace.py", line 1224, in _strict_export
    return _strict_export_lower_to_aten_ir(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/_trace.py", line 1252, in _strict_export_lower_to_aten_ir
    gm_torch_level = _export_to_torch_ir(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/export/_trace.py", line 560, in _export_to_torch_ir
    gm_torch_level, _ = torch._dynamo.export(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 1432, in inner
    result_traced = opt_f(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 465, in _fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 1269, in __call__
    return self._torchdynamo_orig_callable(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 526, in __call__
    return _compile(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 924, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 666, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_utils_internal.py", line 87, in wrapper_function
    return function(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 699, in _compile_inner
    out_code = transform_code_object(code, transform)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 1322, in transform_code_object
    transformations(instructions, code_options)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 219, in _fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 634, in transform
    tracer.run()
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 2796, in run
    super().run()
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 983, in run
    while self.step():
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 895, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 582, in wrapper
    return inner_fn(self, inst)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1680, in CALL_FUNCTION_EX
    self.call_function(fn, argsvars.items, kwargsvars)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 830, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py", line 442, in call_function
    return tx.inline_user_function_return(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 836, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3011, in inline_call
    return cls.inline_call_(parent, func, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3139, in inline_call_
    tracer.run()
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 983, in run
    while self.step():
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 895, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 582, in wrapper
    return inner_fn(self, inst)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1680, in CALL_FUNCTION_EX
    self.call_function(fn, argsvars.items, kwargsvars)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 830, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 385, in call_function
    return super().call_function(tx, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 324, in call_function
    return super().call_function(tx, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py", line 111, in call_function
    return tx.inline_user_function_return(self, [*self.self_args(), *args], kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 836, in inline_user_function_return
    return InliningInstructionTranslator.inline_call(self, fn, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3011, in inline_call
    return cls.inline_call_(parent, func, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 3139, in inline_call_
    tracer.run()
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 983, in run
    while self.step():
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 895, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 582, in wrapper
    return inner_fn(self, inst)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1602, in CALL_FUNCTION
    self.call_function(fn, args, {})
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 830, in call_function
    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/nn_module.py", line 414, in call_function
    return wrap_fx_proxy(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2037, in wrap_fx_proxy
    return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py", line 2124, in wrap_fx_proxy_cls
    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2082, in get_fake_value
    raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2017, in get_fake_value
    ret_val = wrap_fake_exception(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 1574, in wrap_fake_exception
    return fn()
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2018, in <lambda>
    lambda: run_node(tx.output, node, args, kwargs, nnmodule)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2150, in run_node
    raise RuntimeError(make_error_message(e)).with_traceback(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 2137, in run_node
    return nnmodule(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 190, in forward
    return F.embedding(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/utils/_stats.py", line 21, in wrapper
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1238, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1692, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1339, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1943, in _dispatch_impl
    return decomposition_table[func](*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_prims_common/wrappers.py", line 273, in _fn
    result = fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_decomp/decompositions.py", line 1264, in embedding
    return weight[indices]
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/utils/_stats.py", line 21, in wrapper
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1238, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1692, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1348, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1983, in _dispatch_impl
    op_impl_out = op_impl(self, func, *args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_impls.py", line 147, in dispatch_to_op_implementations_dict
    return op_implementations_dict[func](fake_mode, func, *args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_subclasses/fake_impls.py", line 573, in index_tensor
    out = meta_index_Tensor(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/_meta_registrations.py", line 3005, in meta_index_Tensor
    torch._check(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/__init__.py", line 1564, in _check
    _check_with(RuntimeError, cond, message)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/__init__.py", line 1546, in _check_with
    raise error_type(message_evaluated)
torch._dynamo.exc.TorchRuntimeError: Failed running call_module L__self___model_embed_tokens(*(FakeTensor(..., device='cuda:0', size=(8, 111, 3072), dtype=torch.float16),), **{}):
tensors used as indices must be long, int, byte or bool tensors

from user code:
   File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 831, in forward
    outputs = self.model(
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/salmonn/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 545, in forward
    inputs_embeds = self.embed_tokens(input_ids)

Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information